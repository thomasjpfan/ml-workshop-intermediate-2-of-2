{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "plt.rcParams[\"savefig.dpi\"] = 300\n",
    "\n",
    "sklearn.set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curve(y_true, y_prob, n_bins=5, ax=None, hist=True, normalize=False):\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=n_bins, normalize=normalize)\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if hist:\n",
    "        ax.hist(y_prob, weights=np.ones_like(y_prob) / len(y_prob), alpha=.4,\n",
    "               bins=np.maximum(10, n_bins))\n",
    "    ax.plot([0, 1], [0, 1], ':', c='k')\n",
    "    curve = ax.plot(prob_pred, prob_true, marker=\"o\")\n",
    "\n",
    "    ax.set_xlabel(\"predicted probability\")\n",
    "    ax.set_ylabel(\"fraction of positive samples\")\n",
    "\n",
    "    ax.set(aspect='equal')\n",
    "    return curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=10000, n_features=20,\n",
    "                           n_informative=2, n_redundant=2)\n",
    "\n",
    "train_samples = 100  # Samples used for training the models\n",
    "\n",
    "X_train = X[:train_samples]\n",
    "X_test = X[train_samples:]\n",
    "y_train = y[:train_samples]\n",
    "y_test = y[train_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "lr = make_pipeline(StandardScaler(), LogisticRegression(random_state=42))\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_proba = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prod_pred = calibration_curve(y_test, lr_proba[:, 1], n_bins=5)\n",
    "\n",
    "print(prob_true)\n",
    "print(prod_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(y_test, lr_proba[:, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_brier = brier_score_loss(y_test, lr_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 8))\n",
    "plot_calibration_curve(y_test, lr_proba[:, 1], n_bins=5, ax=ax1)\n",
    "ax1.set_title(\"n_bins=5\")\n",
    "plot_calibration_curve(y_test, lr_proba[:, 1], n_bins=10, ax=ax2)\n",
    "ax2.set_title(\"n_bins=10\")\n",
    "plot_calibration_curve(y_test, lr_proba[:, 1], n_bins=30, ax=ax3)\n",
    "ax3.set_title(\"n_bins=30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_proba = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_brier = brier_score_loss(y_test, rf_proba[:, 1])\n",
    "rf_brier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Single Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_proba = tree.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_brier = brier_score_loss(y_test, tree_proba[:, 1])\n",
    "tree_brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 8))\n",
    "plot_calibration_curve(y_test, lr_proba[:, 1], n_bins=10, ax=ax1)\n",
    "ax1.set_title(f\"LogisticRegression: {lr_brier:0.4f}\")\n",
    "plot_calibration_curve(y_test, tree_proba[:, 1], n_bins=10, ax=ax2)\n",
    "ax2.set_title(f\"DecisionTreeClassifier: {tree_brier:0.4f}\")\n",
    "plot_calibration_curve(y_test, rf_proba[:, 1], n_bins=10, ax=ax3)\n",
    "ax3.set_title(f\"RandomForestClassifier: {rf_brier:0.4f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "1. Train a `sklearn.naive_bayes.GaussianNB` on the training set.\n",
    "2. Compute the brier score loss on the test set for the `GuassianNB`.\n",
    "3. Plot the calibration curve with `n_bins=10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/02-ex01-solutions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "cal_rf = CalibratedClassifierCV(rf, method=\"isotonic\")\n",
    "cal_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_rf_proba = cal_rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_rf_brier = brier_score_loss(y_test, cal_rf_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "plot_calibration_curve(y_test, rf_proba[:, 1], ax=ax1, n_bins=10)\n",
    "ax1.set_title(f\"forest no calibration: {rf_brier:0.4f}\")\n",
    "plot_calibration_curve(y_test, cal_rf_proba[:, 1], ax=ax2, n_bins=10)\n",
    "ax2.set_title(f\"isotonic: {cal_rf_brier:0.4f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrating the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = make_pipeline(StandardScaler(), LogisticRegression(random_state=42))\n",
    "cal_lr = CalibratedClassifierCV(lr, method='isotonic')\n",
    "cal_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_lr_proba = cal_lr.predict_proba(X_test)\n",
    "\n",
    "cal_lr_brier = brier_score_loss(y_test, cal_lr_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "plot_calibration_curve(y_test, lr_proba[:, 1], ax=ax1, n_bins=10)\n",
    "ax1.set_title(f\"no calibration: {lr_brier:0.4f}\")\n",
    "plot_calibration_curve(y_test, cal_lr_proba[:, 1], ax=ax2, n_bins=10)\n",
    "ax2.set_title(f\"isotonic: {cal_lr_brier:0.4f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "1. Calibrate the `sklearn.naive_bayes.GaussianNB` on the training set.\n",
    "2. Compute the brier score loss on the test set.\n",
    "3. Plot the calibration curve with `n_bins=10`.\n",
    "4. Did the calibration improve with `CalibratedClassifierCV`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/02-ex02-solutions.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
